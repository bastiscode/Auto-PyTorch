<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Image Classification &#8212; AutoPyTorch 0.0.3 documentation</title>
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-binder.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-dataframe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/gallery-rendered-html.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">
<script type="text/javascript" src="../_static/js/jquery-1.11.0.min.js "></script>
<script type="text/javascript" src="../_static/js/jquery-fix.js "></script>
<script type="text/javascript" src="../_static/bootstrap-3.3.7/js/bootstrap.min.js "></script>
<script type="text/javascript" src="../_static/bootstrap-sphinx.js "></script>

  </head><body>
  
  <a href="https://github.com/automl/Auto-PyTorch"
     class="visible-desktop hidden-xs"><img
    id="gh-banner"
    style="position: absolute; top: 50px; right: 0; border: 0;"
    src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png"
    alt="Fork me on GitHub"></a>
  <script>
    // Adjust banner height.
    $(function () {
      var navHeight = $(".navbar .container").css("height");
      $("#gh-banner").css("top", navHeight);
    });
  </script>


  <div id="navbar" class="navbar navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../index.html">
          Auto-PyTorch</a>
        <span class="navbar-text navbar-version pull-left"><b>0.0.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../index.html">Start</a></li>
                <li><a href="../releases.html">Releases</a></li>
                <li><a href="../installation.html">Installation</a></li>
                <li><a href="../manual.html">Manual</a></li>
                <li><a href="index.html">Examples</a></li>
                <li><a href="../api.html">API</a></li>
                <li><a href="../extending.html">Extending</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../index.html">Site <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"></ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container">
  <div class="row">
      <div class="col-md-3">
        <div id="sidebar" class="bs-sidenav" role="complementary"><ul>
<li><a class="reference internal" href="#">Image Classification</a></li>
</ul>

        </div>
      </div>
    <div class="body col-md-9 content" role="main">
      
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-examples-example-image-classification-py"><span class="std std-ref">here</span></a>
to download the full example code or to run this example in your browser via Binder</p>
</div>
<div class="sphx-glr-example-title section" id="image-classification">
<span id="sphx-glr-examples-example-image-classification-py"></span><h1>Image Classification<a class="headerlink" href="#image-classification" title="Permalink to this headline">Â¶</a></h1>
<p class="sphx-glr-script-out">Out:</p>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz

0it [00:00, ?it/s]
  0%|          | 0/26421880 [00:00&lt;?, ?it/s]
  0%|          | 16384/26421880 [00:00&lt;03:15, 135206.69it/s]
  0%|          | 49152/26421880 [00:00&lt;02:02, 215038.19it/s]
  0%|          | 106496/26421880 [00:00&lt;01:18, 333129.80it/s]
  1%|          | 204800/26421880 [00:00&lt;00:50, 521027.39it/s]
  2%|1         | 425984/26421880 [00:00&lt;00:26, 990331.16it/s]
  3%|3         | 860160/26421880 [00:01&lt;00:13, 1868723.01it/s]
  7%|6         | 1728512/26421880 [00:01&lt;00:06, 3598485.00it/s]
 13%|#3        | 3473408/26421880 [00:01&lt;00:03, 7012760.95it/s]
 25%|##4       | 6561792/26421880 [00:01&lt;00:01, 12814260.15it/s]
 35%|###5      | 9330688/26421880 [00:01&lt;00:01, 15819372.93it/s]
 46%|####6     | 12214272/26421880 [00:01&lt;00:00, 18206314.86it/s]
 58%|#####7    | 15228928/26421880 [00:01&lt;00:00, 20193130.89it/s]
 69%|######9   | 18292736/26421880 [00:01&lt;00:00, 21715722.31it/s]
 81%|########  | 21389312/26421880 [00:02&lt;00:00, 22843075.29it/s]
 92%|#########2| 24412160/26421880 [00:02&lt;00:00, 23488281.90it/s]Extracting ../datasets/FashionMNIST/raw/train-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz


0it [00:00, ?it/s][A

  0%|          | 0/29515 [00:00&lt;?, ?it/s][A

 56%|#####5    | 16384/29515 [00:00&lt;00:00, 134695.74it/s][AExtracting ../datasets/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz



0it [00:00, ?it/s][A[A


  0%|          | 0/4422102 [00:00&lt;?, ?it/s][A[A


  0%|          | 16384/4422102 [00:00&lt;00:33, 133486.94it/s][A[A


  1%|1         | 49152/4422102 [00:00&lt;00:20, 212443.91it/s][A[A


  2%|2         | 106496/4422102 [00:00&lt;00:13, 329446.33it/s][A[A


  5%|4         | 204800/4422102 [00:00&lt;00:08, 516271.09it/s][A[A


 10%|9         | 425984/4422102 [00:00&lt;00:04, 978869.84it/s][A[A


 19%|#9        | 860160/4422102 [00:01&lt;00:01, 1848396.28it/s][A[A


 39%|###9      | 1728512/4422102 [00:01&lt;00:00, 3562138.06it/s][A[A


 79%|#######8  | 3473408/4422102 [00:01&lt;00:00, 6964705.37it/s][A[AExtracting ../datasets/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ../datasets/FashionMNIST/raw
Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz




0it [00:00, ?it/s][A[A[A



  0%|          | 0/5148 [00:00&lt;?, ?it/s][A[A[AExtracting ../datasets/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ../datasets/FashionMNIST/raw
Processing...
/opt/hostedtoolcache/Python/3.8.7/x64/lib/python3.8/site-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)
  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)
Done!

26427392it [00:04, 5499917.41it/s]

32768it [00:02, 14875.60it/s]

4423680it [00:01, 2436145.14it/s]

8192it [00:00, 18288.31it/s]
Pipeline CS:
 ________________________________________
Configuration space object:
  Hyperparameters:
    image_augmenter:GaussianBlur:sigma_min, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.0
    image_augmenter:GaussianBlur:sigma_offset, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.5
    image_augmenter:GaussianBlur:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
    image_augmenter:GaussianNoise:sigma_offset, Type: UniformFloat, Range: [0.0, 3.0], Default: 0.3
    image_augmenter:GaussianNoise:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
    image_augmenter:RandomAffine:rotate, Type: UniformInteger, Range: [0, 360], Default: 45
    image_augmenter:RandomAffine:scale_offset, Type: UniformFloat, Range: [0.0, 0.4], Default: 0.2
    image_augmenter:RandomAffine:shear, Type: UniformInteger, Range: [0, 45], Default: 30
    image_augmenter:RandomAffine:translate_percent_offset, Type: UniformFloat, Range: [0.0, 0.4], Default: 0.2
    image_augmenter:RandomAffine:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
    image_augmenter:RandomCutout:p, Type: UniformFloat, Range: [0.2, 1.0], Default: 0.5
    image_augmenter:RandomCutout:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
    image_augmenter:Resize:use_augmenter, Type: Categorical, Choices: {True, False}, Default: True
    image_augmenter:ZeroPadAndCrop:percent, Type: UniformFloat, Range: [0.0, 0.5], Default: 0.1
    normalizer:__choice__, Type: Categorical, Choices: {ImageNormalizer, NoNormalizer}, Default: ImageNormalizer
  Conditions:
    image_augmenter:GaussianBlur:sigma_min | image_augmenter:GaussianBlur:use_augmenter == True
    image_augmenter:GaussianBlur:sigma_offset | image_augmenter:GaussianBlur:use_augmenter == True
    image_augmenter:GaussianNoise:sigma_offset | image_augmenter:GaussianNoise:use_augmenter == True
    image_augmenter:RandomAffine:rotate | image_augmenter:RandomAffine:use_augmenter == True
    image_augmenter:RandomAffine:scale_offset | image_augmenter:RandomAffine:use_augmenter == True
    image_augmenter:RandomAffine:shear | image_augmenter:RandomAffine:use_augmenter == True
    image_augmenter:RandomAffine:translate_percent_offset | image_augmenter:RandomAffine:use_augmenter == True
    image_augmenter:RandomCutout:p | image_augmenter:RandomCutout:use_augmenter == True

Pipeline Random Config:
 ________________________________________
Configuration:
  image_augmenter:GaussianBlur:sigma_min, Value: 2.0116079836721887
  image_augmenter:GaussianBlur:sigma_offset, Value: 0.12510910970745592
  image_augmenter:GaussianBlur:use_augmenter, Value: True
  image_augmenter:GaussianNoise:sigma_offset, Value: 1.2722721654490763
  image_augmenter:GaussianNoise:use_augmenter, Value: True
  image_augmenter:RandomAffine:rotate, Value: 46
  image_augmenter:RandomAffine:scale_offset, Value: 0.03863365064648634
  image_augmenter:RandomAffine:shear, Value: 13
  image_augmenter:RandomAffine:translate_percent_offset, Value: 0.34196574592037976
  image_augmenter:RandomAffine:use_augmenter, Value: True
  image_augmenter:RandomCutout:use_augmenter, Value: False
  image_augmenter:Resize:use_augmenter, Value: False
  image_augmenter:ZeroPadAndCrop:percent, Value: 0.28871351684109503
  normalizer:__choice__, Value: &#39;NoNormalizer&#39;

Fitting the pipeline...
________________________________________
        ImageClassificationPipeline
________________________________________
0-) normalizer:
        NoNormalizer

1-) preprocessing:
        EarlyPreprocessing

2-) image_augmenter:
        ImageAugmenter

________________________________________
</pre></div>
</div>
<div class="line-block">
<div class="line"><br /></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">import</span> <span class="nn">sklearn.model_selection</span>

<span class="kn">import</span> <span class="nn">torchvision.datasets</span>

<span class="kn">from</span> <span class="nn">autoPyTorch.pipeline.image_classification</span> <span class="kn">import</span> <span class="n">ImageClassificationPipeline</span>

<span class="c1"># Get the training data for tabular classification</span>
<span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">FashionMNIST</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;../datasets/&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">trainset</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="c1"># Create a proof of concept pipeline!</span>
<span class="n">dataset_properties</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">()</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">ImageClassificationPipeline</span><span class="p">(</span><span class="n">dataset_properties</span><span class="o">=</span><span class="n">dataset_properties</span><span class="p">)</span>

<span class="c1"># Train and test split</span>
<span class="n">train_indices</span><span class="p">,</span> <span class="n">val_indices</span> <span class="o">=</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">model_selection</span><span class="o">.</span><span class="n">train_test_split</span><span class="p">(</span>
    <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])),</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
<span class="p">)</span>

<span class="c1"># Configuration space</span>
<span class="n">pipeline_cs</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_hyperparameter_search_space</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pipeline CS:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">pipeline_cs</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">pipeline_cs</span><span class="o">.</span><span class="n">sample_configuration</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Pipeline Random Config:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s1">&#39;_&#39;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="n">config</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">pipeline</span><span class="o">.</span><span class="n">set_hyperparameters</span><span class="p">(</span><span class="n">config</span><span class="p">)</span>

<span class="c1"># Fit the pipeline</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Fitting the pipeline...&quot;</span><span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">X_train</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
                    <span class="n">is_small_preprocess</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                    <span class="n">dataset_properties</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">)]),</span>
                                            <span class="n">std</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">data</span><span class="p">[:,</span> <span class="p">:,</span> <span class="p">:,</span> <span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">)]),</span>
                                            <span class="n">num_classes</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                                            <span class="n">num_features</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                            <span class="n">image_height</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                                            <span class="n">image_width</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                                            <span class="n">is_small_preprocess</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
                    <span class="n">train_indices</span><span class="o">=</span><span class="n">train_indices</span><span class="p">,</span>
                    <span class="n">val_indices</span><span class="o">=</span><span class="n">val_indices</span><span class="p">,</span>
                    <span class="p">)</span>
             <span class="p">)</span>

<span class="c1"># Showcase some components of the pipeline</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  11.507 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-examples-example-image-classification-py">
<div class="binder-badge docutils container">
<a class="reference external image-reference" href="https://mybinder.org/v2/gh/automl/Auto-PyTorch/refactor_development?urlpath=lab/tree/notebooks/examples/example_image_classification.ipynb"><img alt="Launch binder" src="../_images/binder_badge_logo.svg" width="150px" /></a>
</div>
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/3a985c2d5cf88bfc51ae65d16b30f86c/example_image_classification.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">example_image_classification.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/a39c0378d911b81ecec47ff0a116e6bf/example_image_classification.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">example_image_classification.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>


    </div>
      
  </div>
</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
        <br/>
        
<div id="sourcelink">
  <a href="../_sources/examples/example_image_classification.rst.txt"
     rel="nofollow">Source</a>
</div>
      
    </p>
    <p>
        &copy; Copyright 2014-2019, Machine Learning Professorship Freiburg.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 3.4.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>